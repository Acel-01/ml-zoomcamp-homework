{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7496c277-4389-4205-87b6-790afa445d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa498db-b2b5-4d78-a17f-4fae95ad0b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-25 21:39:09--  https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 80876 (79K) [text/plain]\n",
      "Saving to: ‘course_lead_scoring.csv’\n",
      "\n",
      "course_lead_scoring 100%[===================>]  78.98K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2025-10-25 21:39:09 (57.3 MB/s) - ‘course_lead_scoring.csv’ saved [80876/80876]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467d3b75-0cda-4f4c-b220-419016f3cb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f21961b-eea8-4f48-a316-368e038846f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6956ff0b-5fd3-47d5-b917-86eeb4103e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85cbcd5d-3618-49c8-938b-848549d92fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "numerical = list(df.dtypes[df.dtypes != 'object'].index)\n",
    "\n",
    "numerical.remove('converted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25eb789-6686-4483-8098-c5d608dc16f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number_of_courses_viewed',\n",
       " 'annual_income',\n",
       " 'interaction_count',\n",
       " 'lead_score']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42246b73-2f30-49e2-85a4-e2021d6fc9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical features, replace missing values with 'NA'\n",
    "for col in categorical:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "\n",
    "# For numerical features, replace with with 0.0\n",
    "for col in numerical:\n",
    "    df[col] = df[col].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8104b4c-dffb-4bd3-87bd-ab72e4893ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check if all missing values are handled\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8efa5e60-6a56-4dc1-be13-a488f285423c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the mode of the 'industry' column\n",
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a0e4ba7-6aef-42bc-b146-e70a57102e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>-0.023565</td>\n",
       "      <td>-0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>0.009770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>0.015610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>-0.023565</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>-0.004879</td>\n",
       "      <td>0.015610</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          number_of_courses_viewed  annual_income  \\\n",
       "number_of_courses_viewed                  1.000000       0.009770   \n",
       "annual_income                             0.009770       1.000000   \n",
       "interaction_count                        -0.023565       0.027036   \n",
       "lead_score                               -0.004879       0.015610   \n",
       "\n",
       "                          interaction_count  lead_score  \n",
       "number_of_courses_viewed          -0.023565   -0.004879  \n",
       "annual_income                      0.027036    0.015610  \n",
       "interaction_count                  1.000000    0.009888  \n",
       "lead_score                         0.009888    1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "008d2623-383a-4ecf-a343-3437cedea5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Correlations for Question 2 ---\n",
      "'interaction_count' and 'lead_score': 0.0099\n",
      "'number_of_courses_viewed' and 'lead_score': -0.0049\n",
      "'number_of_courses_viewed' and 'interaction_count': -0.0236\n",
      "'annual_income' and 'interaction_count': 0.0270\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix for all numerical features\n",
    "correlation_matrix = df[numerical].corr()\n",
    "\n",
    "# 3. Get the specific correlation values for the pairs in the question\n",
    "pair_1 = correlation_matrix.loc['interaction_count', 'lead_score']\n",
    "pair_2 = correlation_matrix.loc['number_of_courses_viewed', 'lead_score']\n",
    "pair_3 = correlation_matrix.loc['number_of_courses_viewed', 'interaction_count']\n",
    "pair_4 = correlation_matrix.loc['annual_income', 'interaction_count']\n",
    "\n",
    "print(\"--- Correlations for Question 2 ---\")\n",
    "print(f\"'interaction_count' and 'lead_score': {pair_1:.4f}\")\n",
    "print(f\"'number_of_courses_viewed' and 'lead_score': {pair_2:.4f}\")\n",
    "print(f\"'number_of_courses_viewed' and 'interaction_count': {pair_3:.4f}\")\n",
    "print(f\"'annual_income' and 'interaction_count': {pair_4:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9f1c34-9efd-4318-a4cd-7865122ca807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (1462, 8)\n",
      "Training set shape:   (876, 8)\n",
      "Validation set shape: (293, 8)\n",
      "Test set shape:       (293, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1. Define our features (X) and target (y)\n",
    "df_features = df[categorical + numerical]\n",
    "df_target = df['converted']\n",
    "\n",
    "# 2. First split: 60% train_full, 20% test\n",
    "# We set random_state=42 for reproducibility\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(df_features, df_target, \n",
    "                                                              test_size=0.2, \n",
    "                                                              random_state=42)\n",
    "\n",
    "# 3. Second split: Split the 80% train_full set into 75/25 (60% train, 20% val)\n",
    "# Note: 0.25 * 0.8 = 0.2 (which is 20% of the total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, \n",
    "                                                  test_size=0.25, \n",
    "                                                  random_state=42)\n",
    "\n",
    "# 4. Print the sizes of our final sets to confirm\n",
    "print(f\"Full dataset shape: {df_features.shape}\")\n",
    "print(f\"Training set shape:   {X_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}\")\n",
    "print(f\"Test set shape:       {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae9493fd-bddd-481a-9d9e-871c23793f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Mutual Information Scores ---\n",
      "'lead_source': 0.04\n",
      "'industry': 0.01\n",
      "'employment_status': 0.01\n",
      "'location': 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# We will calculate MI only for our categorical features\n",
    "# using only the training data\n",
    "# MI score helps us know which features have more say on the outcome\n",
    "print(\"--- Mutual Information Scores ---\")\n",
    "for col in categorical:\n",
    "    score = mutual_info_score(X_train[col], y_train)\n",
    "    print(f\"'{col}': {round(score, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3546e390-5748-4af5-912c-be25f4943b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy on the validation dataset is: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Create the DictVectorizer. sparse=False means it returns a standard NumPy array.\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# 2. Convert our DataFrames to lists of dictionaries\n",
    "# This is the format DictVectorizer expects\n",
    "X_train_dicts = X_train.to_dict(orient='records')\n",
    "X_val_dicts = X_val.to_dict(orient='records')\n",
    "\n",
    "# 3. Fit and transform the training data\n",
    "X_train_encoded = dv.fit_transform(X_train_dicts)\n",
    "\n",
    "# 4. ONLY transform the validation data (using the rules learned from train)\n",
    "X_val_encoded = dv.transform(X_val_dicts)\n",
    "\n",
    "# 5. Initialize the model with homework parameters\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# 6. Train the model\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# 7. Calculate accuracy on the validation set\n",
    "accuracy = model.score(X_val_encoded, y_val)\n",
    "\n",
    "print(f\"The accuracy on the validation dataset is: {round(accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2cebcd2-a0e7-4acc-9342-c2298b474b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Accuracy: 0.6997\n",
      "\n",
      "Model without 'industry':\n",
      "  New Accuracy = 0.6997\n",
      "  Difference (Original - New) = 0.0000\n",
      "\n",
      "Model without 'employment_status':\n",
      "  New Accuracy = 0.6962\n",
      "  Difference (Original - New) = 0.0034\n",
      "\n",
      "Model without 'lead_score':\n",
      "  New Accuracy = 0.7065\n",
      "  Difference (Original - New) = -0.0068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Our baseline accuracy from Question 4\n",
    "original_accuracy = accuracy # This should be 0.6997... from your last run\n",
    "\n",
    "# The list of features we need to test\n",
    "features_to_test = ['industry', 'employment_status', 'lead_score']\n",
    "\n",
    "print(f\"Original Accuracy: {original_accuracy:.4f}\\n\")\n",
    "\n",
    "# Loop through each feature to remove it\n",
    "for feature in features_to_test:\n",
    "    \n",
    "    # --- 1. Create new datasets WITHOUT the feature ---\n",
    "    # We drop the feature from our original DataFrames\n",
    "    X_train_new = X_train.drop(columns=[feature])\n",
    "    X_val_new = X_val.drop(columns=[feature])\n",
    "    \n",
    "    # --- 2. Re-encode the new data ---\n",
    "    # We must use a NEW vectorizer to learn the new feature set\n",
    "    dv_new = DictVectorizer(sparse=False)\n",
    "    X_train_dicts_new = X_train_new.to_dict(orient='records')\n",
    "    X_val_dicts_new = X_val_new.to_dict(orient='records')\n",
    "    \n",
    "    X_train_encoded_new = dv_new.fit_transform(X_train_dicts_new)\n",
    "    X_val_encoded_new = dv_new.transform(X_val_dicts_new)\n",
    "    \n",
    "    # --- 3. Re-train a new model ---\n",
    "    model_new = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_new.fit(X_train_encoded_new, y_train)\n",
    "    \n",
    "    # --- 4. Get the new accuracy and calculate the difference ---\n",
    "    new_accuracy = model_new.score(X_val_encoded_new, y_val)\n",
    "    difference = original_accuracy - new_accuracy\n",
    "    \n",
    "    print(f\"Model without '{feature}':\")\n",
    "    print(f\"  New Accuracy = {new_accuracy:.4f}\")\n",
    "    print(f\"  Difference (Original - New) = {difference:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea7f5848-7a42-46c7-bc89-f84c78360309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tuning the 'C' parameter ---\n",
      "C = 0.01: \t Accuracy = 0.6997\n",
      "C = 0.1: \t Accuracy = 0.6997\n",
      "C = 1: \t Accuracy = 0.6997\n",
      "C = 10: \t Accuracy = 0.6997\n",
      "C = 100: \t Accuracy = 0.6997\n"
     ]
    }
   ],
   "source": [
    "# The list of C values to test\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "print(\"--- Tuning the 'C' parameter ---\")\n",
    "\n",
    "# Loop through each C value\n",
    "for C in C_values:\n",
    "    # 1. Initialize the model with the specific C value\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    \n",
    "    # 2. Train the model\n",
    "    # We use our original, full-feature training data\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    # 3. Calculate accuracy on the validation set\n",
    "    accuracy = model.score(X_val_encoded, y_val)\n",
    "    \n",
    "    # 4. Print the result\n",
    "    print(f\"C = {C}: \\t Accuracy = {round(accuracy, 4)}\") # \\t adds a nice tab for alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf6ebf-be07-4129-96fc-2461dc735da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
